{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import pickle\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///Messages.db')\n",
    "df = pd.read_sql(\"SELECT * FROM Messages\", engine)\n",
    "\n",
    "X = df['message']\n",
    "Y = df.drop(['id', 'message', 'original', 'genre'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"Normalize, tokenize and stem text string\n",
    "    \n",
    "    Args:\n",
    "    text: string. String containing message for processing\n",
    "       \n",
    "    Returns:\n",
    "    stemmed: list of strings. List containing normalized and stemmed word tokens\n",
    "    \"\"\"\n",
    "    # Convert text to lowercase and remove punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    \n",
    "    # Tokenize words\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Stem word tokens and remove stop words\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    \n",
    "    stemmed = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=71)\n",
    "pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_metrics(actual, predicted, col_names):\n",
    "    \"\"\"Calculate evaluation metrics for ML model\n",
    "    \n",
    "    Args:\n",
    "    actual: array. Array containing actual labels.\n",
    "    predicted: array. Array containing predicted labels.\n",
    "    col_names: list of strings. List containing names for each of the predicted fields.\n",
    "       \n",
    "    Returns:\n",
    "    metrics_df: dataframe. Dataframe containing the accuracy, precision, recall \n",
    "    and f1 score for a given set of actual and predicted labels.\n",
    "    \"\"\"\n",
    "    metrics = []\n",
    "    \n",
    "    # Calculate evaluation metrics for each set of labels\n",
    "    for i in range(len(col_names)):\n",
    "        accuracy = accuracy_score(actual[:, i], predicted[:, i])\n",
    "        precision = precision_score(actual[:, i], predicted[:, i],average='micro')\n",
    "        recall = recall_score(actual[:, i], predicted[:, i],average='micro')\n",
    "        f1 = f1_score(actual[:, i], predicted[:, i],average='micro')\n",
    "        \n",
    "        metrics.append([accuracy, precision, recall, f1])\n",
    "    \n",
    "    # Create dataframe containing metrics\n",
    "    metrics = np.array(metrics)\n",
    "    metrics_df = pd.DataFrame(data = metrics, index = col_names, columns = ['Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "      \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy  Precision    Recall        F1\n",
      "related                 0.990654   0.990654  0.990654  0.990654\n",
      "request                 0.986935   0.986935  0.986935  0.986935\n",
      "offer                   0.998665   0.998665  0.998665  0.998665\n",
      "aid_related             0.984980   0.984980  0.984980  0.984980\n",
      "medical_help            0.988270   0.988270  0.988270  0.988270\n",
      "medical_products        0.991465   0.991465  0.991465  0.991465\n",
      "search_and_rescue       0.993849   0.993849  0.993849  0.993849\n",
      "security                0.994707   0.994707  0.994707  0.994707\n",
      "military                0.996138   0.996138  0.996138  0.996138\n",
      "child_alone             1.000000   1.000000  1.000000  1.000000\n",
      "water                   0.994469   0.994469  0.994469  0.994469\n",
      "food                    0.994373   0.994373  0.994373  0.994373\n",
      "shelter                 0.991799   0.991799  0.991799  0.991799\n",
      "clothing                0.997711   0.997711  0.997711  0.997711\n",
      "money                   0.996138   0.996138  0.996138  0.996138\n",
      "missing_people          0.997044   0.997044  0.997044  0.997044\n",
      "refugees                0.994993   0.994993  0.994993  0.994993\n",
      "death                   0.994803   0.994803  0.994803  0.994803\n",
      "other_aid               0.978924   0.978924  0.978924  0.978924\n",
      "infrastructure_related  0.985409   0.985409  0.985409  0.985409\n",
      "transport               0.991179   0.991179  0.991179  0.991179\n",
      "buildings               0.992180   0.992180  0.992180  0.992180\n",
      "electricity             0.996567   0.996567  0.996567  0.996567\n",
      "tools                   0.997902   0.997902  0.997902  0.997902\n",
      "hospitals               0.996710   0.996710  0.996710  0.996710\n",
      "shops                   0.998713   0.998713  0.998713  0.998713\n",
      "aid_centers             0.996853   0.996853  0.996853  0.996853\n",
      "other_infrastructure    0.990320   0.990320  0.990320  0.990320\n",
      "weather_related         0.989176   0.989176  0.989176  0.989176\n",
      "floods                  0.991799   0.991799  0.991799  0.991799\n",
      "storm                   0.994183   0.994183  0.994183  0.994183\n",
      "fire                    0.997616   0.997616  0.997616  0.997616\n",
      "earthquake              0.996090   0.996090  0.996090  0.996090\n",
      "cold                    0.997234   0.997234  0.997234  0.997234\n",
      "other_weather           0.989605   0.989605  0.989605  0.989605\n",
      "direct_report           0.982405   0.982405  0.982405  0.982405\n"
     ]
    }
   ],
   "source": [
    "Y_train_pred = pipeline.predict(X_train)\n",
    "col_names = list(Y.columns.values)\n",
    "\n",
    "print(get_eval_metrics(np.array(Y_train), Y_train_pred, col_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy  Precision    Recall        F1\n",
      "related                 0.807399   0.807399  0.807399  0.807399\n",
      "request                 0.888635   0.888635  0.888635  0.888635\n",
      "offer                   0.995423   0.995423  0.995423  0.995423\n",
      "aid_related             0.751144   0.751144  0.751144  0.751144\n",
      "medical_help            0.928871   0.928871  0.928871  0.928871\n",
      "medical_products        0.953852   0.953852  0.953852  0.953852\n",
      "search_and_rescue       0.970633   0.970633  0.970633  0.970633\n",
      "security                0.981503   0.981503  0.981503  0.981503\n",
      "military                0.966629   0.966629  0.966629  0.966629\n",
      "child_alone             1.000000   1.000000  1.000000  1.000000\n",
      "water                   0.950610   0.950610  0.950610  0.950610\n",
      "food                    0.938978   0.938978  0.938978  0.938978\n",
      "shelter                 0.934401   0.934401  0.934401  0.934401\n",
      "clothing                0.985889   0.985889  0.985889  0.985889\n",
      "money                   0.978261   0.978261  0.978261  0.978261\n",
      "missing_people          0.988749   0.988749  0.988749  0.988749\n",
      "refugees                0.963959   0.963959  0.963959  0.963959\n",
      "death                   0.964340   0.964340  0.964340  0.964340\n",
      "other_aid               0.865561   0.865561  0.865561  0.865561\n",
      "infrastructure_related  0.939550   0.939550  0.939550  0.939550\n",
      "transport               0.957666   0.957666  0.957666  0.957666\n",
      "buildings               0.951373   0.951373  0.951373  0.951373\n",
      "electricity             0.979596   0.979596  0.979596  0.979596\n",
      "tools                   0.994851   0.994851  0.994851  0.994851\n",
      "hospitals               0.990656   0.990656  0.990656  0.990656\n",
      "shops                   0.996186   0.996186  0.996186  0.996186\n",
      "aid_centers             0.989130   0.989130  0.989130  0.989130\n",
      "other_infrastructure    0.957857   0.957857  0.957857  0.957857\n",
      "weather_related         0.869565   0.869565  0.869565  0.869565\n",
      "floods                  0.943555   0.943555  0.943555  0.943555\n",
      "storm                   0.927536   0.927536  0.927536  0.927536\n",
      "fire                    0.990465   0.990465  0.990465  0.990465\n",
      "earthquake              0.962815   0.962815  0.962815  0.962815\n",
      "cold                    0.981503   0.981503  0.981503  0.981503\n",
      "other_weather           0.947941   0.947941  0.947941  0.947941\n",
      "direct_report           0.835622   0.835622  0.835622  0.835622\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics for test set\n",
    "Y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "eval_metrics0 = get_eval_metrics(np.array(Y_test), Y_test_pred, col_names)\n",
    "print(eval_metrics0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.9578028894292662, total= 1.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.9591617794306966, total= 1.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.9553648068669527, total= 1.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  4.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.9590187383779145, total=  53.5s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  5.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.9582320125876126, total=  54.3s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  6.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.957796852646638, total=  53.7s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  7.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.9563009583750537, total= 1.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  9.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.9581604920612217, total= 1.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 10.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.9557939914163089, total= 1.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 12.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.9596624231154341, total=  53.2s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.960449148905736, total=  53.3s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.9587267525035765, total=  52.9s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.9598054641682163, total= 2.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.9588041767987412, total= 2.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.9570100143061517, total= 2.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.9606637104849092, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.961521956801602, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.9593705293276109, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.9583035331140037, total= 2.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.9601630668001717, total= 2.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.9565092989985694, total= 2.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.9623086825919038, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.9609497925904735, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.9601573676680972, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.958518094693177, total=  55.9s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.9584465741667859, total=  56.0s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.9571530758226037, total=  56.0s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.9640966957516808, total=  49.9s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.9613073952224288, total=  50.4s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.9577253218884121, total=  50.2s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.9589472178515234, total=  55.6s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.9593048204834788, total=  55.6s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.955722460658083, total=  55.5s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.9623802031182949, total=  48.5s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.9612358746960378, total=  48.8s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.9601573676680972, total=  48.4s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.9597339436418252, total= 1.7min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.9593763410098699, total= 1.7min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.9562231759656652, total= 1.7min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.9616649978543842, total= 1.5min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.9619510799599484, total= 1.5min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.959585121602289, total= 1.5min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.9603061078529538, total= 1.7min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.9589472178515235, total= 1.7min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.9587982832618025, total= 1.7min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.962451723644686, total= 1.4min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.9593763410098699, total= 1.4min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.9606580829756796, total= 1.4min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.9583750536403948, total=  53.3s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.9580174510084394, total=  53.1s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.9568669527896996, total=  53.2s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.9625947646974682, total=  49.3s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.9594478615362609, total=  48.6s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.9600143061516453, total=  48.6s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.958518094693177, total=  52.6s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.9589472178515234, total=  52.7s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.9560801144492133, total=  52.2s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.9617365183807753, total=  47.3s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.9620941210127307, total=  47.3s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.959585121602289, total=  47.2s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.9591617794306966, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.9590187383779145, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.9565808297567955, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.9640966957516808, total= 1.4min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.9611643541696466, total= 1.4min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.9620886981402004, total= 1.4min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.9571592046917465, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.9581604920612216, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.9566523605150214, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.963309969961379, total= 1.4min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.9600915462737806, total= 1.4min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.9590128755364806, total= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed: 117.0min finished\n"
     ]
    }
   ],
   "source": [
    "def performance_metric(y_true, y_pred):\n",
    "    \"\"\"Calculate median F1 score for all of the output classifiers\n",
    "    \n",
    "    Args:\n",
    "    y_true: array. Array containing actual labels.\n",
    "    y_pred: array. Array containing predicted labels.\n",
    "        \n",
    "    Returns:\n",
    "    score: float. Median F1 score for all of the output classifiers\n",
    "    \"\"\"\n",
    "    f1_list = []\n",
    "    for i in range(np.shape(y_pred)[1]):\n",
    "        f1 = f1_score(np.array(y_true)[:, i], y_pred[:, i], average='micro')\n",
    "        f1_list.append(f1)\n",
    "        \n",
    "    score = np.median(f1_list)\n",
    "    return score\n",
    "parameters = {'vect__min_df': [1, 5],\n",
    "              'tfidf__use_idf':[True, False],\n",
    "              'clf__estimator__n_estimators':[10, 25], \n",
    "              'clf__estimator__min_samples_split':[2, 5, 10]}\n",
    "\n",
    "scorer = make_scorer(performance_metric)\n",
    "cv = GridSearchCV(pipeline, param_grid = parameters, scoring = scorer, verbose = 10)\n",
    "\n",
    "# Find best parameters\n",
    "np.random.seed(81)\n",
    "tuned_model = cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([  53.9573342 ,   44.3698562 ,   55.05597059,   43.76403928,\n",
       "         110.23458242,   86.67768375,  112.85497705,   85.04113658,\n",
       "          46.11938691,   40.73215914,   45.85723472,   39.29702584,\n",
       "          89.73457734,   77.22345265,   89.91035461,   74.42761525,\n",
       "          43.29196143,   39.31711245,   42.67355021,   37.89729643,\n",
       "          82.88600159,   73.65914329,   81.25589609,   70.59951758]),\n",
       " 'std_fit_time': array([ 0.5798039 ,  0.42277498,  1.0541529 ,  0.28809062,  1.00190523,\n",
       "         0.63061587,  1.28348658,  0.62502073,  0.17015837,  0.21670168,\n",
       "         0.2470712 ,  0.28324009,  0.30669932,  0.39586694,  0.28401311,\n",
       "         0.21909037,  0.18096546,  0.33766019,  0.45599212,  0.17314726,\n",
       "         0.32330257,  0.38148161,  0.30885475,  0.78499402]),\n",
       " 'mean_score_time': array([  9.8821497 ,   9.4619561 ,   9.81571182,   9.39157216,\n",
       "         12.49557217,  11.3044459 ,  12.37783909,  11.45710595,\n",
       "          9.85655427,   9.44431909,   9.71644648,   9.2851193 ,\n",
       "         12.50639049,  11.33873089,  12.26684626,  11.37089602,\n",
       "          9.89115826,   9.50908279,   9.80862037,   9.38920387,\n",
       "         12.57579605,  11.4324638 ,  12.4492836 ,  11.44192783]),\n",
       " 'std_score_time': array([ 0.13644577,  0.21321317,  0.01162734,  0.13113914,  0.10084318,\n",
       "         0.10739277,  0.1938783 ,  0.26395841,  0.13970841,  0.04818372,\n",
       "         0.17993688,  0.12785194,  0.34052425,  0.15938321,  0.07003573,\n",
       "         0.0997352 ,  0.19389386,  0.15618501,  0.23290202,  0.13759998,\n",
       "         0.0919169 ,  0.14245423,  0.13900677,  0.02271794]),\n",
       " 'param_clf__estimator__min_samples_split': masked_array(data = [2 2 2 2 2 2 2 2 5 5 5 5 5 5 5 5 10 10 10 10 10 10 10 10],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_clf__estimator__n_estimators': masked_array(data = [10 10 10 10 25 25 25 25 10 10 10 10 25 25 25 25 10 10 10 10 25 25 25 25],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_tfidf__use_idf': masked_array(data = [True True False False True True False False True True False False True\n",
       "  True False False True True False False True True False False],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_vect__min_df': masked_array(data = [1 5 1 5 1 5 1 5 1 5 1 5 1 5 1 5 1 5 1 5 1 5 1 5],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 5}],\n",
       " 'split0_test_score': array([ 0.95780289,  0.95901874,  0.95630096,  0.95966242,  0.95980546,\n",
       "         0.96066371,  0.95830353,  0.96230868,  0.95851809,  0.9640967 ,\n",
       "         0.95894722,  0.9623802 ,  0.95973394,  0.961665  ,  0.96030611,\n",
       "         0.96245172,  0.95837505,  0.96259476,  0.95851809,  0.96173652,\n",
       "         0.95916178,  0.9640967 ,  0.9571592 ,  0.96330997]),\n",
       " 'split1_test_score': array([ 0.95916178,  0.95823201,  0.95816049,  0.96044915,  0.95880418,\n",
       "         0.96152196,  0.96016307,  0.96094979,  0.95844657,  0.9613074 ,\n",
       "         0.95930482,  0.96123587,  0.95937634,  0.96195108,  0.95894722,\n",
       "         0.95937634,  0.95801745,  0.95944786,  0.95894722,  0.96209412,\n",
       "         0.95901874,  0.96116435,  0.95816049,  0.96009155]),\n",
       " 'split2_test_score': array([ 0.95536481,  0.95779685,  0.95579399,  0.95872675,  0.95701001,\n",
       "         0.95937053,  0.9565093 ,  0.96015737,  0.95715308,  0.95772532,\n",
       "         0.95572246,  0.96015737,  0.95622318,  0.95958512,  0.95879828,\n",
       "         0.96065808,  0.95686695,  0.96001431,  0.95608011,  0.95958512,\n",
       "         0.95658083,  0.9620887 ,  0.95665236,  0.95901288]),\n",
       " 'mean_test_score': array([ 0.95744326,  0.95834923,  0.95675186,  0.95961282,  0.95853996,\n",
       "         0.96051879,  0.95832539,  0.96113866,  0.95803929,  0.9610433 ,\n",
       "         0.95799161,  0.96125787,  0.95844459,  0.96106714,  0.95935056,\n",
       "         0.96082872,  0.95775319,  0.96068568,  0.95784856,  0.96113866,\n",
       "         0.95825386,  0.96244993,  0.95732405,  0.96080488]),\n",
       " 'std_test_score': array([ 0.00157081,  0.00050567,  0.00101736,  0.00070403,  0.00115642,\n",
       "         0.00088426,  0.00149171,  0.00088836,  0.00062728,  0.00260777,\n",
       "         0.00161104,  0.00090759,  0.00157744,  0.00105436,  0.00067843,\n",
       "         0.00126133,  0.00064341,  0.00136964,  0.0012626 ,  0.0011081 ,\n",
       "         0.00118437,  0.0012241 ,  0.00062662,  0.00182534]),\n",
       " 'rank_test_score': array([22, 15, 24, 11, 13, 10, 16,  3, 18,  6, 19,  2, 14,  5, 12,  7, 21,\n",
       "         9, 20,  3, 17,  1, 23,  8], dtype=int32),\n",
       " 'split0_train_score': array([ 0.99456405,  0.99520778,  0.99392032,  0.99531507,  0.99896288,\n",
       "         0.99892712,  0.99881983,  0.99885559,  0.99141692,  0.99016522,\n",
       "         0.99130963,  0.9898076 ,  0.99456405,  0.9919176 ,  0.99341964,\n",
       "         0.99170303,  0.98877047,  0.98712538,  0.9878764 ,  0.98612403,\n",
       "         0.98937844,  0.98809098,  0.98923539,  0.98819827]),\n",
       " 'split1_train_score': array([ 0.99420642,  0.99449253,  0.99488592,  0.99452829,  0.9987483 ,\n",
       "         0.99856949,  0.99867678,  0.99864101,  0.99091624,  0.98977183,\n",
       "         0.99120235,  0.9891281 ,  0.99381303,  0.99241828,  0.99377727,\n",
       "         0.99141692,  0.98791217,  0.98666047,  0.98726844,  0.98658894,\n",
       "         0.99012946,  0.98834132,  0.98905658,  0.9878764 ]),\n",
       " 'split2_train_score': array([ 0.9949578 ,  0.99506508,  0.99392076,  0.99485052,  0.99874839,\n",
       "         0.99871263,  0.99885567,  0.99864111,  0.99188242,  0.99066657,\n",
       "         0.99027321,  0.98998713,  0.99449292,  0.99224002,  0.99342011,\n",
       "         0.99245458,  0.98798455,  0.98701902,  0.98762695,  0.98651838,\n",
       "         0.98984409,  0.98776999,  0.98923616,  0.98794879]),\n",
       " 'mean_train_score': array([ 0.99457609,  0.9949218 ,  0.99424233,  0.99489796,  0.99881986,\n",
       "         0.99873641,  0.99878409,  0.99871257,  0.9914052 ,  0.99020121,\n",
       "         0.9909284 ,  0.98964094,  0.99429   ,  0.99219197,  0.99353901,\n",
       "         0.99185818,  0.9882224 ,  0.98693496,  0.9875906 ,  0.98641045,\n",
       "         0.989784  ,  0.98806743,  0.98917604,  0.98800782]),\n",
       " 'std_train_score': array([  3.06867697e-04,   3.09080597e-04,   4.55083944e-04,\n",
       "          3.22949213e-04,   1.01131439e-04,   1.46966250e-04,\n",
       "          7.72817877e-05,   1.01129631e-04,   3.94527179e-04,\n",
       "          3.66160509e-04,   4.65353700e-04,   3.69964668e-04,\n",
       "          3.38515818e-04,   2.07206602e-04,   1.68476736e-04,\n",
       "          4.37599118e-04,   3.88673831e-04,   1.98892169e-04,\n",
       "          2.49529430e-04,   2.04570697e-04,   3.09532431e-04,\n",
       "          2.33838352e-04,   8.44758271e-05,   1.37871299e-04])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get results of grid search\n",
    "tuned_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96244993324432582"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Best mean test score\n",
    "np.max(tuned_model.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__min_samples_split': 10,\n",
       " 'clf__estimator__n_estimators': 25,\n",
       " 'tfidf__use_idf': True,\n",
       " 'vect__min_df': 5}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters for best mean test score\n",
    "tuned_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy  Precision    Recall        F1\n",
      "related                 0.818841   0.818841  0.818841  0.818841\n",
      "request                 0.892830   0.892830  0.892830  0.892830\n",
      "offer                   0.995423   0.995423  0.995423  0.995423\n",
      "aid_related             0.780320   0.780320  0.780320  0.780320\n",
      "medical_help            0.930015   0.930015  0.930015  0.930015\n",
      "medical_products        0.956903   0.956903  0.956903  0.956903\n",
      "search_and_rescue       0.970633   0.970633  0.970633  0.970633\n",
      "security                0.981503   0.981503  0.981503  0.981503\n",
      "military                0.966629   0.966629  0.966629  0.966629\n",
      "child_alone             1.000000   1.000000  1.000000  1.000000\n",
      "water                   0.963959   0.963959  0.963959  0.963959\n",
      "food                    0.952899   0.952899  0.952899  0.952899\n",
      "shelter                 0.946606   0.946606  0.946606  0.946606\n",
      "clothing                0.985698   0.985698  0.985698  0.985698\n",
      "money                   0.977689   0.977689  0.977689  0.977689\n",
      "missing_people          0.988558   0.988558  0.988558  0.988558\n",
      "refugees                0.964531   0.964531  0.964531  0.964531\n",
      "death                   0.968154   0.968154  0.968154  0.968154\n",
      "other_aid               0.865751   0.865751  0.865751  0.865751\n",
      "infrastructure_related  0.940313   0.940313  0.940313  0.940313\n",
      "transport               0.957094   0.957094  0.957094  0.957094\n",
      "buildings               0.958619   0.958619  0.958619  0.958619\n",
      "electricity             0.979214   0.979214  0.979214  0.979214\n",
      "tools                   0.995042   0.995042  0.995042  0.995042\n",
      "hospitals               0.990656   0.990656  0.990656  0.990656\n",
      "shops                   0.996186   0.996186  0.996186  0.996186\n",
      "aid_centers             0.989130   0.989130  0.989130  0.989130\n",
      "other_infrastructure    0.957857   0.957857  0.957857  0.957857\n",
      "weather_related         0.887300   0.887300  0.887300  0.887300\n",
      "floods                  0.956712   0.956712  0.956712  0.956712\n",
      "storm                   0.943173   0.943173  0.943173  0.943173\n",
      "fire                    0.990656   0.990656  0.990656  0.990656\n",
      "earthquake              0.970252   0.970252  0.970252  0.970252\n",
      "cold                    0.983028   0.983028  0.983028  0.983028\n",
      "other_weather           0.946606   0.946606  0.946606  0.946606\n",
      "direct_report           0.857170   0.857170  0.857170  0.857170\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate evaluation metrics for test set\n",
    "tuned_pred_test = tuned_model.predict(X_test)\n",
    "\n",
    "eval_metrics1 = get_eval_metrics(np.array(Y_test), tuned_pred_test, col_names)\n",
    "\n",
    "print(eval_metrics1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.945297</td>\n",
       "      <td>0.945297</td>\n",
       "      <td>0.945297</td>\n",
       "      <td>0.945297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.056666</td>\n",
       "      <td>0.056666</td>\n",
       "      <td>0.056666</td>\n",
       "      <td>0.056666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.751144</td>\n",
       "      <td>0.751144</td>\n",
       "      <td>0.751144</td>\n",
       "      <td>0.751144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.937834</td>\n",
       "      <td>0.937834</td>\n",
       "      <td>0.937834</td>\n",
       "      <td>0.937834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.960336</td>\n",
       "      <td>0.960336</td>\n",
       "      <td>0.960336</td>\n",
       "      <td>0.960336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.982599</td>\n",
       "      <td>0.982599</td>\n",
       "      <td>0.982599</td>\n",
       "      <td>0.982599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Precision     Recall         F1\n",
       "count  36.000000  36.000000  36.000000  36.000000\n",
       "mean    0.945297   0.945297   0.945297   0.945297\n",
       "std     0.056666   0.056666   0.056666   0.056666\n",
       "min     0.751144   0.751144   0.751144   0.751144\n",
       "25%     0.937834   0.937834   0.937834   0.937834\n",
       "50%     0.960336   0.960336   0.960336   0.960336\n",
       "75%     0.982599   0.982599   0.982599   0.982599\n",
       "max     1.000000   1.000000   1.000000   1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get summary stats for first model\n",
    "eval_metrics0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.950165</td>\n",
       "      <td>0.950165</td>\n",
       "      <td>0.950165</td>\n",
       "      <td>0.950165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.051167</td>\n",
       "      <td>0.051167</td>\n",
       "      <td>0.051167</td>\n",
       "      <td>0.051167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.780320</td>\n",
       "      <td>0.780320</td>\n",
       "      <td>0.780320</td>\n",
       "      <td>0.780320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.945748</td>\n",
       "      <td>0.945748</td>\n",
       "      <td>0.945748</td>\n",
       "      <td>0.945748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.964245</td>\n",
       "      <td>0.964245</td>\n",
       "      <td>0.964245</td>\n",
       "      <td>0.964245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.983696</td>\n",
       "      <td>0.983696</td>\n",
       "      <td>0.983696</td>\n",
       "      <td>0.983696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Precision     Recall         F1\n",
       "count  36.000000  36.000000  36.000000  36.000000\n",
       "mean    0.950165   0.950165   0.950165   0.950165\n",
       "std     0.051167   0.051167   0.051167   0.051167\n",
       "min     0.780320   0.780320   0.780320   0.780320\n",
       "25%     0.945748   0.945748   0.945748   0.945748\n",
       "50%     0.964245   0.964245   0.964245   0.964245\n",
       "75%     0.983696   0.983696   0.983696   0.983696\n",
       "max     1.000000   1.000000   1.000000   1.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get summary stats for tuned model\n",
    "eval_metrics1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 16.34094572,  16.20881581,  16.39457067,  16.26617169,\n",
       "         16.38575109,  16.60354106]),\n",
       " 'std_fit_time': array([ 0.12218311,  0.08752283,  0.15167826,  0.11741955,  0.0499043 ,\n",
       "         0.26169727]),\n",
       " 'mean_score_time': array([ 8.23167491,  8.14754725,  8.19075632,  8.05127184,  8.08176438,\n",
       "         8.14498075]),\n",
       " 'std_score_time': array([ 0.1149151 ,  0.12167545,  0.24817801,  0.21684216,  0.24388543,\n",
       "         0.06132707]),\n",
       " 'param_clf__estimator__alpha': masked_array(data = [0 0 1 1 2 2],\n",
       "              mask = [False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_clf__estimator__fit_prior': masked_array(data = [True False True False True False],\n",
       "              mask = [False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'clf__estimator__alpha': 0, 'clf__estimator__fit_prior': True},\n",
       "  {'clf__estimator__alpha': 0, 'clf__estimator__fit_prior': False},\n",
       "  {'clf__estimator__alpha': 1, 'clf__estimator__fit_prior': True},\n",
       "  {'clf__estimator__alpha': 1, 'clf__estimator__fit_prior': False},\n",
       "  {'clf__estimator__alpha': 2, 'clf__estimator__fit_prior': True},\n",
       "  {'clf__estimator__alpha': 2, 'clf__estimator__fit_prior': False}],\n",
       " 'split0_test_score': array([ 0.14604491,  0.10728079,  0.21556287,  0.20826777,  0.1735088 ,\n",
       "         0.18123301]),\n",
       " 'split1_test_score': array([ 0.14890574,  0.11486197,  0.21298813,  0.21141468,  0.16635674,\n",
       "         0.17365184]),\n",
       " 'split2_test_score': array([ 0.16051502,  0.11959943,  0.20701001,  0.20815451,  0.17353362,\n",
       "         0.18082976]),\n",
       " 'mean_test_score': array([ 0.15182148,  0.11391379,  0.2118539 ,  0.20927904,  0.17113294,\n",
       "         0.17857143]),\n",
       " 'std_test_score': array([ 0.0062568 ,  0.0050735 ,  0.00358258,  0.00151089,  0.00337742,\n",
       "         0.00348269]),\n",
       " 'rank_test_score': array([5, 6, 1, 2, 4, 3], dtype=int32),\n",
       " 'split0_train_score': array([ 0.60331879,  0.57005937,  0.29554395,  0.2842429 ,  0.21750948,\n",
       "         0.23417495]),\n",
       " 'split1_train_score': array([ 0.59151706,  0.56018883,  0.295687  ,  0.28431443,  0.21765253,\n",
       "         0.23360275]),\n",
       " 'split2_train_score': array([ 0.60048634,  0.56093549,  0.29552282,  0.28400801,  0.21599199,\n",
       "         0.23322844]),\n",
       " 'mean_train_score': array([ 0.59844073,  0.56372789,  0.29558459,  0.28418845,  0.21705133,\n",
       "         0.23366871]),\n",
       " 'std_train_score': array([  5.03048069e-03,   4.48739197e-03,   7.29294982e-05,\n",
       "          1.30886134e-04,   7.51341075e-04,   3.89218256e-04])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "pipeline2 = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(BernoulliNB()))\n",
    "    ])\n",
    "\n",
    "parameters2 = {\n",
    "                'clf__estimator__fit_prior': [True, False],\n",
    "                'clf__estimator__alpha': [0, 1, 2],\n",
    "              }\n",
    "\n",
    "cv2 = GridSearchCV(pipeline2, param_grid=parameters2)\n",
    "new_model2 = cv2.fit(X_train, Y_train)\n",
    "new_model2.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__alpha': 1, 'clf__estimator__fit_prior': True}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy  Precision    Recall        F1\n",
      "related                 0.816171   0.816171  0.816171  0.816171\n",
      "request                 0.885011   0.885011  0.885011  0.885011\n",
      "offer                   0.992944   0.992944  0.992944  0.992944\n",
      "aid_related             0.754958   0.754958  0.754958  0.754958\n",
      "medical_help            0.921243   0.921243  0.921243  0.921243\n",
      "medical_products        0.949085   0.949085  0.949085  0.949085\n",
      "search_and_rescue       0.968154   0.968154  0.968154  0.968154\n",
      "security                0.979786   0.979786  0.979786  0.979786\n",
      "military                0.963387   0.963387  0.963387  0.963387\n",
      "child_alone             1.000000   1.000000  1.000000  1.000000\n",
      "water                   0.935355   0.935355  0.935355  0.935355\n",
      "food                    0.907132   0.907132  0.907132  0.907132\n",
      "shelter                 0.919718   0.919718  0.919718  0.919718\n",
      "clothing                0.983028   0.983028  0.983028  0.983028\n",
      "money                   0.974447   0.974447  0.974447  0.974447\n",
      "missing_people          0.986461   0.986461  0.986461  0.986461\n",
      "refugees                0.961861   0.961861  0.961861  0.961861\n",
      "death                   0.957666   0.957666  0.957666  0.957666\n",
      "other_aid               0.854882   0.854882  0.854882  0.854882\n",
      "infrastructure_related  0.930969   0.930969  0.930969  0.930969\n",
      "transport               0.952326   0.952326  0.952326  0.952326\n",
      "buildings               0.948894   0.948894  0.948894  0.948894\n",
      "electricity             0.976545   0.976545  0.976545  0.976545\n",
      "tools                   0.993135   0.993135  0.993135  0.993135\n",
      "hospitals               0.988177   0.988177  0.988177  0.988177\n",
      "shops                   0.994470   0.994470  0.994470  0.994470\n",
      "aid_centers             0.987414   0.987414  0.987414  0.987414\n",
      "other_infrastructure    0.955568   0.955568  0.955568  0.955568\n",
      "weather_related         0.815408   0.815408  0.815408  0.815408\n",
      "floods                  0.916095   0.916095  0.916095  0.916095\n",
      "storm                   0.912853   0.912853  0.912853  0.912853\n",
      "fire                    0.988368   0.988368  0.988368  0.988368\n",
      "earthquake              0.919527   0.919527  0.919527  0.919527\n",
      "cold                    0.979214   0.979214  0.979214  0.979214\n",
      "other_weather           0.943555   0.943555  0.943555  0.943555\n",
      "direct_report           0.841533   0.841533  0.841533  0.841533\n"
     ]
    }
   ],
   "source": [
    "new_Y_pred2 = new_model2.predict(X_test)\n",
    "\n",
    "new_metrics2 = []\n",
    "for i in range(len(Y_test.columns)):\n",
    "    accuracy = accuracy_score(Y_test.iloc[:, i], new_Y_pred2[:, i])\n",
    "    precision = precision_score(Y_test.iloc[:, i], new_Y_pred2[:, i], average='micro')\n",
    "    recall = recall_score(Y_test.iloc[:, i], new_Y_pred2[:, i], average='micro')\n",
    "    f1 = f1_score(Y_test.iloc[:, i], new_Y_pred2[:, i], average='micro')\n",
    "    new_metrics2.append([accuracy, precision, recall, f1])\n",
    "\n",
    "new_metrics_df2 = pd.DataFrame(data=np.array(new_metrics2), index=list(Y_test.columns.values), columns = ['Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "print(new_metrics_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.937648</td>\n",
       "      <td>0.937648</td>\n",
       "      <td>0.937648</td>\n",
       "      <td>0.937648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.058552</td>\n",
       "      <td>0.058552</td>\n",
       "      <td>0.058552</td>\n",
       "      <td>0.058552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.754958</td>\n",
       "      <td>0.754958</td>\n",
       "      <td>0.754958</td>\n",
       "      <td>0.754958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.918669</td>\n",
       "      <td>0.918669</td>\n",
       "      <td>0.918669</td>\n",
       "      <td>0.918669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.953947</td>\n",
       "      <td>0.953947</td>\n",
       "      <td>0.953947</td>\n",
       "      <td>0.953947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.980597</td>\n",
       "      <td>0.980597</td>\n",
       "      <td>0.980597</td>\n",
       "      <td>0.980597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Precision     Recall         F1\n",
       "count  36.000000  36.000000  36.000000  36.000000\n",
       "mean    0.937648   0.937648   0.937648   0.937648\n",
       "std     0.058552   0.058552   0.058552   0.058552\n",
       "min     0.754958   0.754958   0.754958   0.754958\n",
       "25%     0.918669   0.918669   0.918669   0.918669\n",
       "50%     0.953947   0.953947   0.953947   0.953947\n",
       "75%     0.980597   0.980597   0.980597   0.980597\n",
       "max     1.000000   1.000000   1.000000   1.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_metrics_df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tuned_model, open('disaster_pipeline.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
